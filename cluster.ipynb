{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from joblib import Memory\n",
    "import joblib\n",
    "from joblib import Parallel,delayed\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import time\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, MeanShift, estimate_bandwidth,SpectralClustering,OPTICS,AgglomerativeClustering,Birch\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import json\n",
    "\n",
    "from minisom import MiniSom\n",
    "from somlearn import SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all datatsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    did             name  version uploader  status format  MajorityClassSize  \\\n2     2           anneal        1        1  active   ARFF              684.0   \n3     3         kr-vs-kp        1        1  active   ARFF             1669.0   \n4     4            labor        1        1  active   ARFF               37.0   \n5     5       arrhythmia        1        1  active   ARFF              245.0   \n6     6           letter        1        1  active   ARFF              813.0   \n7     7        audiology        1        1  active   ARFF               57.0   \n8     8  liver-disorders        1        1  active   ARFF                NaN   \n9     9            autos        1        1  active   ARFF               67.0   \n10   10            lymph        1        1  active   ARFF               81.0   \n11   11    balance-scale        1        1  active   ARFF              288.0   \n\n    MaxNominalAttDistinctValues  MinorityClassSize  NumberOfClasses  \\\n2                           7.0                8.0              5.0   \n3                           3.0             1527.0              2.0   \n4                           3.0               20.0              2.0   \n5                          13.0                2.0             13.0   \n6                          26.0              734.0             26.0   \n7                          24.0                1.0             24.0   \n8                           NaN                NaN              0.0   \n9                          22.0                3.0              6.0   \n10                          8.0                2.0              4.0   \n11                          3.0               49.0              3.0   \n\n    NumberOfFeatures  NumberOfInstances  NumberOfInstancesWithMissingValues  \\\n2               39.0              898.0                               898.0   \n3               37.0             3196.0                                 0.0   \n4               17.0               57.0                                56.0   \n5              280.0              452.0                               384.0   \n6               17.0            20000.0                                 0.0   \n7               70.0              226.0                               222.0   \n8                6.0              345.0                                 0.0   \n9               26.0              205.0                                46.0   \n10              19.0              148.0                                 0.0   \n11               5.0              625.0                                 0.0   \n\n    NumberOfMissingValues  NumberOfNumericFeatures  NumberOfSymbolicFeatures  \n2                 22175.0                      6.0                      33.0  \n3                     0.0                      0.0                      37.0  \n4                   326.0                      8.0                       9.0  \n5                   408.0                    206.0                      74.0  \n6                     0.0                     16.0                       1.0  \n7                   317.0                      0.0                      70.0  \n8                     0.0                      6.0                       0.0  \n9                    59.0                     15.0                      11.0  \n10                    0.0                      3.0                      16.0  \n11                    0.0                      4.0                       1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>did</th>\n      <th>name</th>\n      <th>version</th>\n      <th>uploader</th>\n      <th>status</th>\n      <th>format</th>\n      <th>MajorityClassSize</th>\n      <th>MaxNominalAttDistinctValues</th>\n      <th>MinorityClassSize</th>\n      <th>NumberOfClasses</th>\n      <th>NumberOfFeatures</th>\n      <th>NumberOfInstances</th>\n      <th>NumberOfInstancesWithMissingValues</th>\n      <th>NumberOfMissingValues</th>\n      <th>NumberOfNumericFeatures</th>\n      <th>NumberOfSymbolicFeatures</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>anneal</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>684.0</td>\n      <td>7.0</td>\n      <td>8.0</td>\n      <td>5.0</td>\n      <td>39.0</td>\n      <td>898.0</td>\n      <td>898.0</td>\n      <td>22175.0</td>\n      <td>6.0</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>kr-vs-kp</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>1669.0</td>\n      <td>3.0</td>\n      <td>1527.0</td>\n      <td>2.0</td>\n      <td>37.0</td>\n      <td>3196.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>37.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>labor</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>37.0</td>\n      <td>3.0</td>\n      <td>20.0</td>\n      <td>2.0</td>\n      <td>17.0</td>\n      <td>57.0</td>\n      <td>56.0</td>\n      <td>326.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>arrhythmia</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>245.0</td>\n      <td>13.0</td>\n      <td>2.0</td>\n      <td>13.0</td>\n      <td>280.0</td>\n      <td>452.0</td>\n      <td>384.0</td>\n      <td>408.0</td>\n      <td>206.0</td>\n      <td>74.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>letter</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>813.0</td>\n      <td>26.0</td>\n      <td>734.0</td>\n      <td>26.0</td>\n      <td>17.0</td>\n      <td>20000.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>16.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>audiology</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>57.0</td>\n      <td>24.0</td>\n      <td>1.0</td>\n      <td>24.0</td>\n      <td>70.0</td>\n      <td>226.0</td>\n      <td>222.0</td>\n      <td>317.0</td>\n      <td>0.0</td>\n      <td>70.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>liver-disorders</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>345.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>autos</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>67.0</td>\n      <td>22.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>26.0</td>\n      <td>205.0</td>\n      <td>46.0</td>\n      <td>59.0</td>\n      <td>15.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>lymph</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>81.0</td>\n      <td>8.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>19.0</td>\n      <td>148.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>balance-scale</td>\n      <td>1</td>\n      <td>1</td>\n      <td>active</td>\n      <td>ARFF</td>\n      <td>288.0</td>\n      <td>3.0</td>\n      <td>49.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>625.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_df = openml.datasets.list_datasets(output_format=\"dataframe\")\n",
    "datasets_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = openml.datasets.get_dataset(26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k='nursery.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print description about dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is dataset 'nursery', the target feature is 'class'\n",
      "URL: https://www.openml.org/data/v1/download/26/nursery.arff\n",
      "**Author**:   \n",
      "**Source**: Unknown -   \n",
      "**Please cite**:   \n",
      "\n",
      "1. Title: Nursery Database\n",
      " \n",
      " 2. Sources:\n",
      "    (a) Creator: Vladislav Rajkovic et al. (13 experts)\n",
      "    (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)\n",
      "                Blaz Zupan      (blaz.zupan@ijs.si)\n",
      "    (c) Date: June, 1997\n",
      " \n",
      " 3. Past Usage:\n",
      " \n",
      "    The hierarchical decision model, from which this dataset is\n",
      "    derived, was first presented in \n",
      " \n",
      "    M. Olave, V. Rajkovic, M. Bohanec: An application for admission in\n",
      "    public school systems. In (I. Th. M. Snellen and W. B. H. J. van de\n",
      "    Donk and J.-P. Baquiast, editors) Expert Systems in Public\n",
      "    Administration, pages 145-160. Elsevier Science Publishers (North\n",
      "    Holland)}, 1989.\n",
      " \n",
      "    Within machine-learning, this dataset was used for the evaluation\n",
      "    of HINT (Hierarchy INduction Tool), which was proved to be able to\n",
      "    completely reconstruct the original hierarchical model. This,\n",
      "    together with a comparison with C4.5, is presented in\n",
      " \n",
      "    B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n",
      "    function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n",
      " \n",
      " 4. Relevant Information Paragraph:\n",
      " \n",
      "    Nursery Database was derived from a hierarchical decision model\n",
      "    originally developed to rank applications for nursery schools. It\n",
      "    was used during several years in 1980's when there was excessive\n",
      "    enrollment to these schools in Ljubljana, Slovenia, and the\n",
      "    rejected applications frequently needed an objective\n",
      "    explanation. The final decision depended on three subproblems:\n",
      "    occupation of parents and child's nursery, family structure and\n",
      "    financial standing, and social and health picture of the family.\n",
      "    The model was developed within expert system shell for decision\n",
      "    making DEX (M. Bohanec, V. Rajkovic: Expert system for decision\n",
      "    making. Sistemica 1(1), pp. 145-157, 1990.).\n",
      " \n",
      "    The hierarchical model ranks nursery-school applications according\n",
      "    to the following concept structure:\n",
      " \n",
      "    NURSERY            Evaluation of applications for nursery schools\n",
      "    . EMPLOY           Employment of parents and child's nursery\n",
      "    . . parents        Parents' occupation\n",
      "    . . has_nurs       Child's nursery\n",
      "    . STRUCT_FINAN     Family structure and financial standings\n",
      "    . . STRUCTURE      Family structure\n",
      "    . . . form         Form of the family\n",
      "    . . . children     Number of children\n",
      "    . . housing        Housing conditions\n",
      "    . . finance        Financial standing of the family\n",
      "    . SOC_HEALTH       Social and health picture of the family\n",
      "    . . social         Social conditions\n",
      "    . . health         Health conditions\n",
      " \n",
      "    Input attributes are printed in lowercase. Besides the target\n",
      "    concept (NURSERY) the model includes four intermediate concepts:\n",
      "    EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in\n",
      "    the original model related to its lower level descendants by a set\n",
      "    of examples (for these examples sets see \n",
      "    http://www-ai.ijs.si/BlazZupan/nursery.html).\n",
      " \n",
      "    The Nursery Database contains examples with the structural\n",
      "    information removed, i.e., directly relates NURSERY to the eight input\n",
      "    attributes: parents, has_nurs, form, children, housing, finance,\n",
      "    social, health.\n",
      " \n",
      "    Because of known underlying concept structure, this database may be\n",
      "    particularly useful for testing constructive induction and\n",
      "    structure discovery methods.\n",
      " \n",
      " 5. Number of Instances: 12960\n",
      "    (instances completely cover the attribute space)\n",
      " \n",
      " 6. Number of Attributes: 8\n",
      " \n",
      " 7. Attribute Values:\n",
      " \n",
      "    parents        usual, pretentious, great_pret\n",
      "    has_nurs       proper, less_proper, improper, critical, very_crit\n",
      "    form           complete, completed, incomplete, foster\n",
      "    children       1, 2, 3, more\n",
      "    housing        convenient, less_conv, critical\n",
      "    finance        convenient, inconv\n",
      "    social         non-prob, slightly_prob, problematic\n",
      "    health         recommended, priority, not_recom\n",
      " \n",
      " 8. Missing Attribute Values: none\n",
      " \n",
      " 9. Class Distribution (number of instances per class)\n",
      " \n",
      "    class        N         N[%]\n",
      "    ------------------------------\n",
      "    not_recom    4320   (33.333 %)\n",
      "    recommend       2   ( 0.015 %)\n",
      "    very_recom    328   ( 2.531 %)\n",
      "    priority     4266   (32.917 %)\n",
      "    spec_prior   4044   (31.204 %)\n",
      "\n",
      " Information about the dataset\n",
      " CLASSTYPE: nominal\n",
      " CLASSINDEX: last\n"
     ]
    }
   ],
   "source": [
    "# Print a summary\n",
    "print(\n",
    "    f\"This is dataset '{dataset.name}', the target feature is \"\n",
    "    f\"'{dataset.default_target_attribute}'\"\n",
    ")\n",
    "print(f\"URL: {dataset.url}\")\n",
    "print(dataset.description[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get depent and indepent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "    dataset_format=\"dataframe\", target=dataset.default_target_attribute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "parents     category\nhas_nurs    category\nform        category\nchildren    category\nhousing     category\nfinance     category\nsocial      category\nhealth      category\ndtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'usual'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-7f5310eb6b55>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'parents'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'parents'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   5546\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5547\u001B[0m             \u001B[1;31m# else, only a single dtype is given\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5548\u001B[1;33m             \u001B[0mnew_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_mgr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5549\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_constructor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnew_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__finalize__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5550\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    602\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"raise\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    603\u001B[0m     ) -> \"BlockManager\":\n\u001B[1;32m--> 604\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"astype\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    605\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    606\u001B[0m     def convert(\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001B[0m in \u001B[0;36mapply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    407\u001B[0m                 \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    408\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 409\u001B[1;33m                 \u001B[0mapplied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    410\u001B[0m             \u001B[0mresult_blocks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_extend_blocks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mapplied\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult_blocks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    411\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    568\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_extension\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m                 \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mValueError\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001B[0m in \u001B[0;36mastype\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m    476\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_integer_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misna\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    477\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Cannot convert float NaN to integer\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 478\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    479\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    480\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mcache_readonly\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001B[0m in \u001B[0;36m__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1252\u001B[0m         \u001B[0mret\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtake_1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcategories\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_codes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1253\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdtype\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_dtype_equal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcategories\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1254\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mret\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1255\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_extension_array_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mret\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1256\u001B[0m             \u001B[1;31m# When we're a Categorical[ExtensionArray], like Interval,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\uc file\\Intern ship\\projects\\Quarterly_median_rents-Analysis-\\venv\\lib\\site-packages\\numpy\\core\\_asarray.py\u001B[0m in \u001B[0;36masarray\u001B[1;34m(a, dtype, order)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \"\"\"\n\u001B[1;32m---> 83\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     84\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: 'usual'"
     ]
    }
   ],
   "source": [
    "x['parents'] = x['parents'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all categorical columns\n",
    "cat_columns = x.select_dtypes(['category']).columns\n",
    "\n",
    "#convert all categorical columns to numeric\n",
    "x[cat_columns] = x[cat_columns].apply(lambda x: pd.factorize(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(x['health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change response variable to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.map({'not_recom' :0,'recommend':1,'very_recom' :2,'priority' :3,'spec_prior' :4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_max_scaled = x.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_min_max_scaled.columns:\n",
    "    df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())    \n",
    "  \n",
    "# view normalized data\n",
    "print(df_min_max_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel(n_jobs=8,backend='multiprocessing'){\n",
    "#     delayed\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_min_max_scaled.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "k_means_model = []\n",
    "clust=[]\n",
    "cluster_center=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def k_means(data,num_clusters):\n",
    "    km = KMeans(n_clusters=num_clusters,\n",
    "                max_iter=10000)\n",
    "    km.fit(data)\n",
    "    cluster_center.append(km.cluster_centers_)\n",
    "#     clusters = km.labels_\n",
    "    k_means_model.append(km)\n",
    "    clust.append(km.labels_)\n",
    "    distortions.append(km.inertia_)\n",
    "    print(clust)\n",
    "    return k_means_model,distortions,clust,cluster_center\n",
    "k_means_result=Parallel(n_jobs=8)(delayed(k_means)(x,num_clusters=i) for i in tqdm(range(2,9)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[1] for i in k_means_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model=tuple([i[0] for i in k_means_result])\n",
    "distortions=([i[1] for i in k_means_result])\n",
    "clust=([i[2] for i in k_means_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model_new=[] \n",
    "def change2(i):\n",
    "    k_means_model_new.append(k_means_model[i][0])\n",
    "    return k_means_model_new\n",
    "Parallel(n_jobs=8,require='sharedmem')(delayed(change2)(i) for i in range(7))\n",
    "# silhouette_scores_new=silhouette_scores_new[0][0]\n",
    "k_means_model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average silhouette_score change with clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = Parallel(n_jobs=8)(delayed(silhouette_score)(x ,model.labels_) for model in k_means_model_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "silhouette_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Average silhouette_score vs no of cluster\")\n",
    "plt.plot(range(2,9), silhouette_scores, \"bo-\", color='blue',linewidth=3,markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means determined value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labelk=[]\n",
    "cluster_center=[]\n",
    "def kmean(data,num_clusters):\n",
    "    km = KMeans(n_clusters=num_clusters,max_iter=10000)\n",
    "    km.fit(data)\n",
    "    labelk.append(km.labels_)\n",
    "    cluster_center.append(km.cluster_centers_)\n",
    "    return labelk,cluster_center\n",
    "labelk=Parallel(n_jobs=8)(delayed(kmean)(x,num_clusters=6) for _ in range(1))[0]\n",
    "end = time.time()\n",
    "kmean_time=end-start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted1=labelk[0][0]\n",
    "predicted1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], c=predicted1, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers=labelk[1][0]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection ='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], marker ='o')\n",
    "ax.scatter(cluster_centers[:, 0], cluster_centers[:, 1],\n",
    "           cluster_centers[:, 2], marker ='x', color ='red',\n",
    "           s = 300, linewidth = 5, zorder = 10)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_f1=f1_score(y, predicted1,average='macro')\n",
    "kmeans_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_adjust=adjusted_rand_score(y,predicted1)\n",
    "kmeans_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_sil=silhouette_score(x,predicted1)\n",
    "kmeans_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'K Means',\n",
    "    'time': kmean_time,\n",
    "    'f1_score':kmeans_f1,\n",
    "    'adjusted_rand_score':kmeans_adjust,\n",
    "    'silhouette_score':kmeans_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels=[]\n",
    "def aggloc(i):\n",
    "    aggloclust=AgglomerativeClustering(n_clusters=i).fit(x)\n",
    "    print(aggloclust)\n",
    "    labels.append(aggloclust.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(aggloc)(6) for _ in range(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "\n",
    "def aggloc(i):\n",
    "    aggloclust=AgglomerativeClustering(n_clusters=i).fit(x)\n",
    "    print(aggloclust)\n",
    "    labels.append(aggloclust.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(aggloc)(6) for _ in range(1))[0]\n",
    "# time.sleep(3)\n",
    "end = time.time()\n",
    "agglo_time=end-start\n",
    "# print(\"--- %s seconds ---\"% (kmean_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2=np.array(labels[0])\n",
    "predicted2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array = np.where(predicted2==0, 5, predicted2)\n",
    "an_array2=np.where(an_array==1, 0, an_array)\n",
    "predicted2_new=np.where(an_array2==5, 1, an_array2)\n",
    "predicted2_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_f1=f1_score(y, predicted2,average='macro')\n",
    "agglo_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, predicted2_new,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_adjust=adjusted_rand_score(y,predicted2)\n",
    "agglo_adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(y,predicted2_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agglo_sil=silhouette_score(x,predicted2)\n",
    "agglo_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_score(x,predicted2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Agglomerative',\n",
    "    'time': agglo_time,\n",
    "    'f1_score':agglo_f1,\n",
    "    'adjusted_rand_score':agglo_adjust,\n",
    "    'silhouette_score':agglo_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIn samples is 2*2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find eps value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = NearestNeighbors(n_neighbors=4)\n",
    "neighbors_fit = neighbors.fit(x)\n",
    "distances, indices = neighbors_fit.kneighbors(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renge_eps=[0.22,0.229,0.239,0.249,0.255,0.265,0.27] #iris dataset ,min_samples=5\n",
    "# renge_eps=[0.45,0.49,0.5,0.504,0.505]  #wine data set optimam 0.504,min_samples=5\n",
    "# renge_eps=[0.3,0.303,0.4] # glass data set optimam 0.3 ,min_samples=2 renge_eps=[0.3,0.303,0.4]\n",
    "# renge_eps=[0.27,0.28,0.3,0.4,0.32] #haberman\n",
    "#renge_eps=[0.412] #satelite \n",
    "# renge_eps=np.arange(2,15,0.1)\n",
    "# renge_eps=[0.77,0.775,0.779,0.78] for gas drift\n",
    "for i in renge_eps:\n",
    "    db = DBSCAN(eps=i,min_samples=8).fit(x)\n",
    "    mask=np.zeros_like(db.labels_,dtype=bool)\n",
    "    mask[db.core_sample_indices_]=True\n",
    "    labels=db.labels_\n",
    "    n_cluster=len(np.unique(labels))\n",
    "    if(len(np.unique(labels))>0):\n",
    "        print('eps value is '+ str(i))\n",
    "        print(set(labels))\n",
    "        avg=silhouette_score(x,labels)\n",
    "        len(np.unique(labels))\n",
    "        print(avg)\n",
    "        print('Number of cluster ',n_cluster )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sample=range(2,10)\n",
    "for i in min_sample:\n",
    "        print('Min sample is '+ str(i))\n",
    "        db = DBSCAN(eps=0.775,min_samples=i).fit(x)\n",
    "        mask=np.zeros_like(db.labels_,dtype=bool)\n",
    "        mask[db.core_sample_indices_]=True\n",
    "        labels=db.labels_\n",
    "        if(len(np.unique(labels))>1):\n",
    "            avg=silhouette_score(x,labels)\n",
    "            len(np.unique(labels))\n",
    "            \n",
    "        \n",
    "        print(\"For min sample values\"+str(i),\"Total no of clusters are \"+str(len(np.unique(labels))))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "\n",
    "def scan(i):\n",
    "    db = DBSCAN(eps=0.775,min_samples=i)\n",
    "    db.fit(x)\n",
    "    labels = db.labels_\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(scan)(6) for _ in range(1))[0]\n",
    "n_cluster=len(np.unique(labels))\n",
    "print(\"Number of clusters: \",n_cluster )\n",
    "end = time.time()\n",
    "dbscan_time=end-start\n",
    "dbscan_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted3=np.array(labels[0])\n",
    "# predicted3\n",
    "predicted3=labels\n",
    "predicted3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], c=predicted3, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_f1=f1_score(y, predicted3,average='macro')\n",
    "dbscan_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_adjust=adjusted_rand_score(y,predicted3)\n",
    "dbscan_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_sil=silhouette_score(x,predicted3)\n",
    "dbscan_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'dbscan',\n",
    "    'time': dbscan_time,\n",
    "    'f1_score':dbscan_f1,\n",
    "    'adjusted_rand_score':dbscan_adjust,\n",
    "    'silhouette_score':dbscan_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renge_eps=range(2,15)           #renge_eps=range(2,25) for glass\n",
    "                                #renge_eps=range(16,40)  for haberman\n",
    "                                #min_samples=i,xi=0.11) satelite\n",
    "for i in renge_eps:\n",
    "    db = OPTICS(min_samples=i,xi=0.11).fit(x)\n",
    "    labels=db.labels_\n",
    "    n_cluster=len(np.unique(labels))\n",
    "    \n",
    "    if(n_cluster==6):\n",
    "        avg=silhouette_score(x,labels)            #n_cluster==3 and avg>0.4 for iris\n",
    "        print(i)\n",
    "        print(set(labels))\n",
    "        print('Number of cluster ',n_cluster )\n",
    "        print(\"for eps value \"+str(i),\"Average silvate score is \",avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for satelit image\n",
    "# 0.1\n",
    "# 0.07\n",
    "# 0.09\n",
    "# 0.08\n",
    "# xi=0.03, clusters=6 sil=-0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def clus():\n",
    "    clustering = OPTICS(min_samples=6).fit(x)    #min_samples=6,xi=0.08\n",
    "    labels.append(clustering.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(clus)() for _ in range(1))[0]\n",
    "end = time.time()\n",
    "optics_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster=len(np.unique(labels))\n",
    "print(\"Number of clusters: \",n_cluster )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted4=np.array(labels)[0]\n",
    "Optics_sil=silhouette_score(x,predicted4)\n",
    "Optics_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted4=np.array(labels)[0]\n",
    "predicted4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:,0], x[:,1], c=predicted4, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optics_f1=f1_score(y, predicted4,average='macro')\n",
    "Optics_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optics_adjust=adjusted_rand_score(y,predicted4)\n",
    "Optics_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Optics_sil=silhouette_score(x,predicted4)\n",
    "Optics_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Optics',\n",
    "    'time': optics_time,\n",
    "    'f1_score':Optics_f1,\n",
    "    'adjusted_rand_score':Optics_adjust,\n",
    "    'silhouette_score':Optics_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def gauss(i):\n",
    "    gmm = GaussianMixture(n_components=i).fit(x)\n",
    "    labels.append(gmm.predict(x))\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(gauss)(6) for _ in range(1))[0][0]\n",
    "end = time.time()\n",
    "GaussianMixture_time=end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted5 = labels\n",
    "predicted5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=predicted5, s=40, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianMixture_f1=f1_score(y, predicted5,average='macro')\n",
    "GaussianMixture_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianMixture_adjust=adjusted_rand_score(y,predicted5)\n",
    "GaussianMixture_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianMixture_sil=silhouette_score(x,predicted5)\n",
    "GaussianMixture_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'GaussianMixture',\n",
    "    'time': GaussianMixture_time,\n",
    "    'f1_score':GaussianMixture_f1,\n",
    "    'adjusted_rand_score':GaussianMixture_adjust,\n",
    "    'silhouette_score':GaussianMixture_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the kernel bandwidth parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import  estimate_bandwidth\n",
    "bandwidth = estimate_bandwidth(x,quantile=0.5)\n",
    "bandwidth\n",
    "labels1=[]\n",
    "cluster_center=[]\n",
    "bandwidth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def mean(i):\n",
    "    ms=MeanShift(bandwidth,cluster_all=True)                #bandwidth=0.31223 for iris\n",
    "                                                 #andwidth=0.778  for wine\n",
    "                                                 #bandwidth=0.6165\n",
    "                                                #bandwidth=0.47 for haberman\n",
    "                                                #bbandwidth=0.749 for satelite\n",
    "                                                #bandwidth=0.8195 for nurse\n",
    "    ms.fit(x)\n",
    "    labels1.append(ms.labels_)\n",
    "    cluster_center.append(ms.cluster_centers_)\n",
    "    return cluster_center,labels1\n",
    "result1=Parallel(n_jobs=8)(delayed(mean)(3) for _ in range(1))[0]\n",
    "end = time.time()\n",
    "MeanShift_time=end-start\n",
    "MeanShift_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanShift_sil=silhouette_score(x,result1[1][0])\n",
    "print(MeanShift_sil)\n",
    "predicted6=result1[1][0]\n",
    "n_cluster=len(np.unique(predicted6))\n",
    "print(\"Number of clusters: \",n_cluster )\n",
    "MeanShift_sil=silhouette_score(x,predicted6)\n",
    "MeanShift_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted6=result1[1][0]\n",
    "n_cluster=len(np.unique(predicted6))\n",
    "print(\"Number of clusters: \",n_cluster )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center=result1[0][0]\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers=result1[0][0]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection ='3d')\n",
    "ax.scatter(x[:, 0], x[:, 1], x[:, 2], marker ='o')\n",
    "ax.scatter(cluster_centers[:, 0], cluster_centers[:, 1],\n",
    "           cluster_centers[:, 2], marker ='x', color ='red',\n",
    "           s = 300, linewidth = 5, zorder = 10)\n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanShift_f1=f1_score(y, predicted6,average='macro')\n",
    "MeanShift_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanShift_adjust=adjusted_rand_score(y,predicted6)\n",
    "MeanShift_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MeanShift_sil=silhouette_score(x,predicted6)\n",
    "MeanShift_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'MeanShift',\n",
    "    'time': MeanShift_time,\n",
    "    'f1_score':MeanShift_f1,\n",
    "    'adjusted_rand_score':MeanShift_adjust,\n",
    "    'silhouette_score':MeanShift_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "cluster_center=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "def affinity(i):\n",
    "    af = AffinityPropagation(preference=-5,random_state=None)      #iris data (preference=-3,random_state=None)\n",
    "                                                                    # wine (preference=-5,random_state=None)\n",
    "                                                                    #preference=-9,random_state=None   haberman\n",
    "                                                                    #preference=-9,random_state=None for satelite\n",
    "    af.fit(x)\n",
    "    labels.append(af.labels_)\n",
    "    cluster_center.append(af.cluster_centers_)\n",
    "    return cluster_center,labels\n",
    "result2=Parallel(n_jobs=8)(delayed(affinity)(6) for _ in range(1))[0]\n",
    "end = time.time()\n",
    "affinity_time=end-start\n",
    "affinity_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted7=result2[1][0]\n",
    "affinity_sil=silhouette_score(x,predicted7)\n",
    "n_cluster=len(np.unique(predicted6))\n",
    "print(\"Number of clusters: \",n_cluster )\n",
    "affinity_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center=result2[0][0]\n",
    "print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted7=result2[1][0]\n",
    "predicted7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=predicted7, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_f1=f1_score(y, predicted7,average='macro')\n",
    "affinity_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_adjust=adjusted_rand_score(y,predicted7)\n",
    "affinity_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_sil=silhouette_score(x,predicted7)\n",
    "affinity_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Affinity_Propagation',\n",
    "    'time': affinity_time,\n",
    "    'f1_score':affinity_f1,\n",
    "    'adjusted_rand_score':affinity_adjust,\n",
    "    'silhouette_score':affinity_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def spect(i):\n",
    "    sc = SpectralClustering(n_clusters = i)\n",
    "    sc.fit(x)\n",
    "    labels.append(sc.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(spect)(6) for _ in range(1))[0][0]\n",
    "end = time.time()\n",
    "Spectral_time=end-start\n",
    "Spectral_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted8=labels\n",
    "predicted8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=predicted8, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectral_f1=f1_score(y, predicted8,average='macro')\n",
    "Spectral_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectral_adjust=adjusted_rand_score(y,predicted8)\n",
    "Spectral_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spectral_sil=silhouette_score(x,predicted8)\n",
    "Spectral_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Spectral',\n",
    "    'time': Spectral_time,\n",
    "    'f1_score':Spectral_f1,\n",
    "    'adjusted_rand_score':Spectral_adjust,\n",
    "    'silhouette_score':Spectral_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def birch(i):\n",
    "    br = Birch(n_clusters = i,threshold=0.327) #0.327\n",
    "    br.fit(x)\n",
    "    labels.append(br.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(aggloc)(6) for _ in range(1))[0][0]\n",
    "end = time.time()\n",
    "Birch_time=end-start\n",
    "Birch_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted9=labels\n",
    "plt.scatter(x[:, 0], x[:, 1], c=predicted9, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Birch_f1=f1_score(y, predicted8,average='macro')\n",
    "Birch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Birch_adjust=adjusted_rand_score(y,predicted8)\n",
    "Birch_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Birch_sil=silhouette_score(x,predicted8)\n",
    "Birch_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Birch',\n",
    "    'time': Birch_time,\n",
    "    'f1_score':Birch_f1,\n",
    "    'adjusted_rand_score':Birch_adjust,\n",
    "    'silhouette_score':Birch_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ward hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandgram=sch.dendrogram(sch.linkage(x,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def ward(i):\n",
    "    Agglomerat=AgglomerativeClustering(n_clusters=i,affinity='euclidean',linkage='ward').fit(x)\n",
    "    labels.append(Agglomerat.labels_)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(ward)(6) for _ in range(1))[0]\n",
    "end = time.time()\n",
    "ward_time=end-start\n",
    "ward_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted10=labels[0]\n",
    "predicted10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=predicted10, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ward_f1=f1_score(y, predicted10,average='macro')\n",
    "Ward_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ward_adjust=adjusted_rand_score(y,predicted10)\n",
    "Ward_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ward_sil=silhouette_score(x,predicted10)\n",
    "Ward_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'Ward',\n",
    "    'time': ward_time,\n",
    "    'f1_score':Ward_f1,\n",
    "    'adjusted_rand_score':Ward_adjust,\n",
    "    'silhouette_score':Ward_sil \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self organizing map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "labels=[]\n",
    "def self(i):\n",
    "    som = SOM(n_columns=5, n_rows=1, random_state=2)   #2 dimention 5 ouput so (n_columns=5, n_rows=1, random_state=2)\n",
    "    labels = som.fit_predict(x)\n",
    "    return labels\n",
    "labels=Parallel(n_jobs=8)(delayed(self)(6) for _ in range(1))[0]\n",
    "end = time.time()\n",
    "self_time=end-start\n",
    "self_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted11=labels\n",
    "predicted11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], x[:, 1], c=predicted11, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_f1=f1_score(y, predicted11,average='macro')\n",
    "self_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjusted_rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_adjust=adjusted_rand_score(y,predicted11)\n",
    "self_adjust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sil=silhouette_score(x,predicted11)\n",
    "self_sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details = {\n",
    "    'name': 'self',\n",
    "    'time': self_time,\n",
    "    'f1_score':self_f1,\n",
    "    'adjusted_rand_score':self_adjust,\n",
    "    'silhouette_score':self_adjust \n",
    "}\n",
    "with open(k, 'a') as json_file:\n",
    "    json.dump(details, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Clustering)",
   "language": "python",
   "name": "pycharm-8122eebd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}